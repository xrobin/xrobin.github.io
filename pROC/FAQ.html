<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FAQ - Frequently asked questions - pROC</title>
    <link href="../css/pROC.css" rel="stylesheet" type="text/css">
    <link href="../css/FAQ.css" rel="stylesheet" type="text/css">
    <link href="http://xavier.robin.name/feed/tag/pROC" rel="alternate" type="application/atom+xml">
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebPage",
      "name": "FAQ - Frequently asked questions - pROC",
      "description": "Frequently asked questions about the pROC R package for displaying and analyzing ROC curves",
      "url": "https://xrobin.github.io/pROC/FAQ.html",
      "mainEntity": {
        "@type": "FAQPage",
        "mainEntity": [
          {
            "@type": "Question",
            "name": "The X axis should be \"1-Specificity\" instead of \"Specificity\"!",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "This is not a bug! Most statistical tools cannot plot specificity from 1 to 0, so instead they plot 1-specificity from 0 to 1. This results in exactly the same plot, just with a different labelling of the axis. R doesn't have this limitation, and pROC plots specificity from 1 to 0, saving you from doing a few subtractions when you look at the plot. If you are using pROC in S+, you only have the choice to plot 1-specificity. If you are concerned that your reviewers will be confused and really wish to have the \"old-style\" 1-Specificity from 0 to 1, or if you plan to change the axis label to \"False Positive Rate\" (which is really 1-specificity), you can use the legacy.axis argument to the plot function. See ?plot.roc for more details."
            }
          },
          {
            "@type": "Question",
            "name": "I have a GLM/SVM/PLS/ model, how can I analyze it with pROC?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "You need to use the predict() function to get predictions that can be passed to pROC (as the predictor argument). Specifically you need to get a single vector of numeric predictions. In some cases you may have to add pass type=\"probabilities\" or something similar to the predict function (to get probabilities instead of the binary response), sometimes you may to have select one of the column of the returned matrix (if predict returns a matrix of class probabilities). Read the documentation of the package you're using and look at your results to find out what to do exactly."
            }
          },
          {
            "@type": "Question",
            "name": "Can I create a ROC curve with two predictors? Can I adjust fixed / random effects in pROC?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "Not directly, but you can! You need to use a modeling function (such as glm()) or package (such as lme4); fit and check the model, then use the predict() function to get predictions that can be passed to pROC (as the predictor argument)."
            }
          },
          {
            "@type": "Question",
            "name": "When I resample or randomize my dataset I get an biased AUC > 0.5. How come?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "This is because pROC tries to auto-detect the direction of the decision due to the default value of direction=\"auto\". The decision is based on the median of the groups instead of the AUC directly, so you the effect may not be 1:1, but you should expect to obtain AUC > 0.5 on average. Whenever you are resampling with pROC you need to explicitly pass an explicit value to direction, either direction=\"<\" or direction=\">\". I also recommend taking a minute to set the levels (value of the response for controls and cases, respectively) argument explicitly too. A future version of pROC will be more verbose and print a message when auto-detecting the direction."
            }
          },
          {
            "@type": "Question",
            "name": "Can I test if a single ROC curve is significantly different from 0.5?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "This is equivalent to asking whether the median values of cases and controls are significantly different. Therefore you can easily perform a Wilcoxon Rank Sum Test."
            }
          },
          {
            "@type": "Question",
            "name": "My dataset is huge. Can I use pROC?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "A large effort has been made to render pROC more and more efficient with large ROC curves. An algorithm with complexity of O(n) has been rolled out with pROC 1.6 and improved over time. Improvements to the DeLong test and the coords functions have been implemented too. If you feel that a function is abnormally slow, especially in comparison to other packages, feel free to open a bug report."
            }
          },
          {
            "@type": "Question",
            "name": "Can I compute the confidence interval of the best threshold of the curve (not its SE/SP)?",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "Yes you can since pROC 1.6 and its ci.coords function. For instance: ci.coords(aSAH$outcome, aSAH$s100b, x=\"best\", input = \"threshold\", ret=\"threshold\") There is 95% chance that the optimal threshold lies between 0.115 and 0.4854."
            }
          },
          {
            "@type": "Question",
            "name": "The functions are giving me weird error messages I don't understand",
            "acceptedAnswer": {
              "@type": "Answer",
              "text": "Several packages on CRAN provide alternative roc or auc functions. These packages can interfere with pROC, especially if they are loaded later in the session (and hence appear earlier in the search path). If that happens, you should unload the package by typing detach(\"package:AUC\"). To find out where the function is coming from, simply type its name on the R prompt. Alternatively you can refer to the pROC version of the function specifically through their namespace: pROC::auc(pROC::roc(aSAH$outcome, aSAH$ndka))"
            }
          }
        ]
      },
      "breadcrumb": {
        "@type": "BreadcrumbList",
        "itemListElement": [
          {
            "@type": "ListItem",
            "position": 1,
            "name": "Xavier Robin",
            "item": "https://xavier.robin.name/"
          },
          {
            "@type": "ListItem",
            "position": 2,
            "name": "Personal Projects",
            "item": "https://xrobin.github.io/"
          },
          {
            "@type": "ListItem",
            "position": 3,
            "name": "pROC",
            "item": "https://xrobin.github.io/pROC/"
          },
          {
            "@type": "ListItem",
            "position": 4,
            "name": "FAQ",
            "item": "https://xrobin.github.io/pROC/FAQ.html"
          }
        ]
      }
    }
    </script>
</head>
<body>

<header class="hero">
    <div class="container">
        <div class="hero-content">
            <a href="../">
                <img src="https://avatars.githubusercontent.com/u/1047170?v=4" alt="" class="hero-avatar">
            </a>
            <div class="hero-text">
                <h1>pROC</h1>
                <p class="hero-subtitle">Frequently asked questions</p>
            </div>
        </div>
    </div>
</header>

<main class="container">
    <section>
        <h2>Frequently asked questions</h2>
        
        <div class="info-card">
            <h3 id="x-axis-specificity">The X axis should be "1-Specificity" instead of "Specificity"!</h3>
            <p>This is <strong>not a bug</strong>!</p>
            <p>Most statistical tools cannot plot specificity from 1 to 0, so instead they plot 1-specificity from 0 to 1. This results in exactly the same plot, just with a different labelling of the axis.</p>
            <p>R doesn't have this limitation, and <code>pROC</code> plots specificity from 1 to 0, saving you from doing a few subtractions when you look at the plot. If you are using pROC in S+, you only have the choice to plot 1-specificity.</p>
            <p>If you are concerned that your reviewers will be confused and really wish to have the "old-style" 1-Specificity from 0 to 1, or if you plan to change the axis label to "False Positive Rate" (which is really 1-specificity), you can use the <code>legacy.axis</code> argument to the plot function. See <code>?plot.roc</code> for more details.</p>
        </div>

        <div class="info-card">
            <h3 id="glm-svm-pls-models">I have a GLM/SVM/PLS/ model, how can I analyze it with pROC?</h3>
            <p>You need to use the <code>predict()</code> function to get predictions that can be passed to pROC (as the <code>predictor</code> argument).</p>
            <p>Specifically you need to get a single vector of numeric predictions. In some cases you may have to add pass <code>type="probabilities"</code> or something similar to the <code>predict</code> function (to get probabilities instead of the binary response), sometimes you may to have select one of the column of the returned matrix (if <code>predict</code> returns a matrix of class probabilities). Read the documentation of the package you're using and look at your results to find out what to do exactly.</p>
        </div>

        <div class="info-card">
            <h3 id="two-predictors">Can I create a ROC curve with two predictors? Can I adjust fixed / random effects in pROC?</h3>
            <p>Not directly, but you can! You need to use a modeling function (such as <code>glm()</code>) or package (such as lme4); fit and check the model, then use the <code>predict()</code> function to get predictions that can be passed to pROC (as the <code>predictor</code> argument).</p>
        </div>

        <div class="info-card">
            <h3 id="resample-randomize">When I resample or randomize my dataset I get an biased AUC > 0.5. How come?</h3>
            <p>This is because pROC tries to auto-detect the direction of the decision due to the default value of <code>direction="auto"</code>. The decision is based on the median of the groups instead of the AUC directly, so you the effect may not be 1:1, but you should expect to obtain AUC > 0.5 on average.</p>
            <p>Whenever you are resampling with pROC you need to explicitly pass an explicit value to <code>direction</code>, either <code>direction="<"</code> or <code>direction=">"</code>. I also recommend taking a minute to set the <code>levels</code> (value of the <code>response</code> for controls and cases, respectively) argument explicitly too.</p>
            <p>A future version of pROC will be more verbose and print a message when auto-detecting the direction.</p>
        </div>

        <div class="info-card">
            <h3 id="test-single-roc">Can I test if a single ROC curve is significantly different from 0.5?</h3>
            <p>This is equivalent to asking whether the median values of cases and controls are significantly different. Therefore you can easily perform a Wilcoxon Rank Sum Test.</p>
        </div>

        <div class="info-card">
            <h3 id="huge-dataset">My dataset is huge. Can I use pROC?</h3>
            <p>A large effort has been made to render pROC more and more efficient with large ROC curves. An algorithm with complexity of O(n) has been rolled out with pROC 1.6 and improved over time. Improvements to the DeLong test and the <code>coords</code> functions have been implemented too.</p>
            <p>If you feel that a function is abnormally slow, especially in comparison to other packages, feel free to open a bug report.</p>
        </div>

        <div class="info-card">
            <h3 id="ci-best-threshold">Can I compute the confidence interval of the best threshold of the curve (not its SE/SP)?</h3>
            <p>Yes you can since pROC 1.6 and its <code>ci.coords</code> function. For instance:</p>
            <pre><code>&gt; ci.coords(aSAH$outcome, aSAH$s100b, x="best", input = "threshold", ret="threshold")
95% CI (2000 stratified bootstrap replicates):
           2.5%   50%  97.5%
threshold 0.115 0.205 0.4854</code></pre>
            <p>There is 95% chance that the optimal threshold lies between 0.115 and 0.4854.</p>
        </div>

        <div class="info-card">
            <h3 id="weird-error-messages">The functions are giving me weird error messages I don't understand</h3>
            <p>Several packages on CRAN provide alternative <code>roc</code> or <code>auc</code> functions. These packages can interfere with pROC, especially if they are loaded later in the session (and hence appear earlier in the search path).</p>
            <p>For instance, here are a few messages you may see if you have the <code>AUC</code> package loaded:</p>
            <blockquote>
                <p>Not enough distinct predictions to compute area under the ROC curve.</p>
                <p>Error in roc(outcome ~ ndka, data = aSAH) : unused argument (data = aSAH)</p>
            </blockquote>
            <p>If that happens, you should unload the package by typing <code>detach("package:AUC")</code>. To find out where the function is coming from, simply type its name on the R prompt:</p>
            <pre><code>&gt; roc
function (predictions, labels)
{
[function code]
}
&lt;bytecode: 0x7fdb71d32ed0&gt;
&lt;environment: namespace:AUC&gt;</code></pre>
            <p>The line at the bottom indicates that the function comes from the AUC package.</p>
            <p>In addition, you may have defined a <code>roc</code> function yourself. In this case, <code>rm(roc)</code> will solve the problem.</p>
            <p>Alternatively you can refer to the pROC version of the function specifically through their namespace:</p>
            <pre><code>pROC::auc(pROC::roc(aSAH$outcome, aSAH$ndka))</code></pre>
            <p>Here is a list of packages providing <code>roc</code>, <code>auc</code> and <code>ci</code> functions which will hide pROC's functions if the package is loaded after pROC:</p>
            <table class="package-table">
                <thead>
                    <tr>
                        <th>Package</th>
                        <th>roc</th>
                        <th>auc</th>
                        <th>ci</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>analogue</td><td>Generic</td><td></td><td></td></tr>
                    <tr><td>asbio</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>AUC</td><td>Not Generic</td><td>Not Generic</td><td></td></tr>
                    <tr><td>aucm</td><td>NA</td><td>NA</td><td></td></tr>
                    <tr><td>cutpointr</td><td>Not Generic</td><td></td><td></td></tr>
                    <tr><td>distillery</td><td></td><td></td><td>Generic</td></tr>
                    <tr><td>enrichvs</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>epiDisplay</td><td>NA</td><td></td><td>Generic</td></tr>
                    <tr><td>esvis</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>FFTrees</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>flux</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>fmsb</td><td>Not Generic</td><td></td><td></td></tr>
                    <tr><td>gmodels</td><td></td><td></td><td>Generic</td></tr>
                    <tr><td>grpreg</td><td></td><td>NA</td><td></td></tr>
                    <tr><td>hutils</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>kulife</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>longROC</td><td>Not Generic</td><td>Not Generic</td><td></td></tr>
                    <tr><td>MAMSE</td><td>Not Generic</td><td></td><td></td></tr>
                    <tr><td>MESS</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>Metrics</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>MXM</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>ncvreg</td><td></td><td>NA</td><td></td></tr>
                    <tr><td>NEArender</td><td>Not Generic</td><td></td><td></td></tr>
                    <tr><td>PK</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>precrec</td><td></td><td>Generic</td><td></td></tr>
                    <tr><td>PresenceAbsence</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>radiant.model</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>RMediation</td><td></td><td></td><td>Not Generic</td></tr>
                    <tr><td>sdm</td><td>Generic</td><td></td><td></td></tr>
                    <tr><td>SDMTools</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>spatstat</td><td></td><td>Generic</td><td></td></tr>
                    <tr><td>StatMeasures</td><td></td><td>Not Generic</td><td></td></tr>
                    <tr><td>survMisc</td><td></td><td></td><td>Generic</td></tr>
                </tbody>
            </table>
            <p>To get an updated list, run <code>inst/extra/sos_clashes.R</code>. It may be needed to start R with <code>export R_MAX_NUM_DLLS=1000</code> to be able to run the script.</p>
        </div>
    </section>
</main>

</body>
</html>

